[DIRECTORIES]
; path to the directory containing the datasets
sandbox_dir = datasets
; path inside the sandbox directory to the directory containing the tables
tables_dir = Quintet
; path to the directory where the results will be saved
output_dir = output_quintet
; path inside the output directory to the directory where the results will be saved
results_dir = results 
; path inside the output directory to the directory where the logs will be saved
logs_dir = logs 
; path inside the output directory to the directory where the aggregated lake will be temporarily saved
aggregated_lake_path = aggregated_lake 
; name of the dirty files
dirty_files_name = dirty.csv 
; name of the clean files
clean_files_name = clean.csv 

[TABLE_GROUPING]
; 1 if table grouping is enabled, 0 otherwise
tg_enabled = 1
; 1 if table grouping results are available, 0 otherwise. If 1, the table grouping step will be skipped and the results will be loaded from the output directory
tg_res_available = 0
; method used for table grouping. if you want to use santos, you need to install it first using make setup-santos
tg_method = bert 

[COLUMN_GROUPING]
; 1 if column grouping is enabled, 0 otherwise
cg_enabled = 1
; 1 if column grouping results are available, 0 otherwise. If 1, the column grouping step will be skipped and the results will be loaded from the output directory
cg_res_available = 0
; minimum number of labels per column cluster
min_num_labes_per_col_cluster = 2 
; clustering algorithm used for column grouping. Possible values: hac, km
cg_clustering_alg = hac 

[CELL_GROUPING]
; 1 if cell feature generator is enabled, 0 otherwise
cell_feature_generator_enabled = 1 
; Not used
cell_clustering_alg = km 
; 1 if cell grouping results are available, 0 otherwise. If 1, the cell grouping step will be skipped and the results will be loaded from the output directory
cell_clustering_res_available = 0

; 0 -> one classifier per column group, 1-> one classifier per column
classification_mode = 0

; 1 for learning methods 0, and 1
labels_per_cell_group = 1

[RAHA]
save_results = 0
strategy_filtering = 0
error_detection_algorithms = OD, RVD

[EXPERIMENTS]
; name of the experiment
exp_name = spell_checker
; number of labels to be used 
labeling_budget = 2000
; number of cores to be used
n_cores = 128
; 1 if the intermediate results should be saved on disk, 0 otherwise
save_mediate_res_on_disk = 1
; generate the final result dataframe. 1 if yes, 0 otherwise. It gives you a table that has a complete information for each cell and also for each table but it might take too long to generate it
final_result_df = 0
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results/scores_all.pickle', 'rb') as f:\n",
    "    scores = pickle.load(f)\n",
    "scores\n",
    "\n",
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results/labeled_by_user.pickle', 'rb') as f:\n",
    "    labeled_by_user = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_samples': 117,\n",
       " 'total_recall': 0.960021831082003,\n",
       " 'total_precision': 0.40828642720362096,\n",
       " 'total_fscore': 0.5729175148603535,\n",
       " 'total_tp': 7036,\n",
       " 'total_fp': 10197,\n",
       " 'total_tn': 441439,\n",
       " 'total_fn': 293}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('3', '0'): [0],\n",
       " ('3', '1'): [0, 0],\n",
       " ('3', '2'): [0, 0],\n",
       " ('3', '3'): [0],\n",
       " ('3', '4'): [0],\n",
       " ('3', '5'): [0],\n",
       " ('3', '6'): [0],\n",
       " ('3', '7'): [0],\n",
       " ('3', '8'): [0, 0],\n",
       " ('3', '9'): [0, 0],\n",
       " ('3', '10'): [0, 0],\n",
       " ('3', '11'): [0, 0],\n",
       " ('3', '12'): [0],\n",
       " ('1', '0'): [0, 0],\n",
       " ('1', '1'): [0, 0],\n",
       " ('1', '2'): [0, 0],\n",
       " ('1', '3'): [0, 0],\n",
       " ('1', '4'): [0, 0],\n",
       " ('1', '5'): [0, 0],\n",
       " ('1', '6'): [0, 0],\n",
       " ('1', '7'): [0, 0],\n",
       " ('1', '8'): [0, 0],\n",
       " ('1', '9'): [0, 0],\n",
       " ('1', '10'): [0, 0],\n",
       " ('1', '11'): [0, 0],\n",
       " ('1', '12'): [1, 1],\n",
       " ('1', '13'): [0, 0],\n",
       " ('1', '14'): [1, 0],\n",
       " ('1', '15'): [1, 1],\n",
       " ('1', '16'): [0, 0],\n",
       " ('1', '17'): [0, 0],\n",
       " ('1', '18'): [0, 0],\n",
       " ('1', '19'): [0, 0],\n",
       " ('1', '20'): [0, 0],\n",
       " ('1', '21'): [0, 0],\n",
       " ('1', '22'): [0, 0],\n",
       " ('1', '23'): [0, 0],\n",
       " ('2', '0'): [0, 0],\n",
       " ('2', '1'): [0, 0],\n",
       " ('2', '2'): [0, 0],\n",
       " ('2', '3'): [0, 1],\n",
       " ('2', '4'): [0, 0],\n",
       " ('2', '5'): [0, 0],\n",
       " ('2', '6'): [0, 1],\n",
       " ('0', '0'): [0, 0],\n",
       " ('0', '1'): [0, 0],\n",
       " ('0', '2'): [0, 0],\n",
       " ('0', '3'): [0, 0],\n",
       " ('0', '4'): [0, 0],\n",
       " ('0', '5'): [0, 0],\n",
       " ('0', '6'): [0, 0],\n",
       " ('0', '7'): [0, 0],\n",
       " ('0', '8'): [0, 0],\n",
       " ('0', '9'): [0, 0],\n",
       " ('0', '10'): [0, 0],\n",
       " ('0', '11'): [0, 0],\n",
       " ('0', '12'): [1, 0],\n",
       " ('0', '13'): [0, 0],\n",
       " ('0', '14'): [1, 1],\n",
       " ('0', '15'): [0, 0],\n",
       " ('0', '16'): [0, 0],\n",
       " ('0', '17'): [0, 1]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_by_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "\n",
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/noises_dict.pickle', 'rb') as f:\n",
    "    noises_dict = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(noises_dict, orient='index').T\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(\"***************************************************************\")\n",
    "    print(row['table_cluster'], row['col_cluster'])\n",
    "    count = 0\n",
    "    for j in row['noise_status'].keys():\n",
    "        if row['noise_status'][j] == True:\n",
    "            count += 1\n",
    "    print(count)\n",
    "    # for i in row['error_ratio'].keys():\n",
    "    #     if row['error_ratio'][i] and row['error_ratio'][i] > 0:\n",
    "    #         print(i, row['error_ratio'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table Column Grouping Res Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_cluster_label</th>\n",
       "      <th>col_value</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_path</th>\n",
       "      <th>table_cluster</th>\n",
       "      <th>col_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>[NEAR EAST, CIS (FORMER USSR), OCEANIA, WESTER...</td>\n",
       "      <td>920d7f742dc7fc3aa6ca183ca630c4d8</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>[Lesotho, Guyana, Eswatini, South Korea, Kirib...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15</td>\n",
       "      <td>[LSO, GUY, SWZ, KOR, KIR, FSM, LTU, SUR, RUS, ...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15</td>\n",
       "      <td>[LS, GY, SZ, KR, KI, FM, LT, SR, RU, ZA, UA, B...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15</td>\n",
       "      <td>[Africa, South America, Africa, Asia, Oceania,...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>[Southern Africa, South America, Central Ameri...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>[Sub-Saharan Africa, Latin America, Sub-Sahara...</td>\n",
       "      <td>5a831f38d322323bc8aeef9790da4111</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>[Shanghai, Yunnan, Beijing, Zhejiang, Jilin, S...</td>\n",
       "      <td>6b4b915850836047cbb546c20c7442d3</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15</td>\n",
       "      <td>[Mainland China, nan, Mainland China, Taiwan, ...</td>\n",
       "      <td>6b4b915850836047cbb546c20c7442d3</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>[IL, KG, FJ, IT, SD, RU, MD, BD, LK, CL, FR, I...</td>\n",
       "      <td>920d7f742dc7fc3aa6ca183ca630c4d8</td>\n",
       "      <td>/home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_cluster_label                                          col_value  \\\n",
       "23                   15  [NEAR EAST, CIS (FORMER USSR), OCEANIA, WESTER...   \n",
       "24                   15  [Lesotho, Guyana, Eswatini, South Korea, Kirib...   \n",
       "25                   15  [LSO, GUY, SWZ, KOR, KIR, FSM, LTU, SUR, RUS, ...   \n",
       "26                   15  [LS, GY, SZ, KR, KI, FM, LT, SR, RU, ZA, UA, B...   \n",
       "27                   15  [Africa, South America, Africa, Asia, Oceania,...   \n",
       "28                   15  [Southern Africa, South America, Central Ameri...   \n",
       "29                   15  [Sub-Saharan Africa, Latin America, Sub-Sahara...   \n",
       "30                   15  [Shanghai, Yunnan, Beijing, Zhejiang, Jilin, S...   \n",
       "31                   15  [Mainland China, nan, Mainland China, Taiwan, ...   \n",
       "32                   15  [IL, KG, FJ, IT, SD, RU, MD, BD, LK, CL, FR, I...   \n",
       "\n",
       "                            table_id  \\\n",
       "23  920d7f742dc7fc3aa6ca183ca630c4d8   \n",
       "24  5a831f38d322323bc8aeef9790da4111   \n",
       "25  5a831f38d322323bc8aeef9790da4111   \n",
       "26  5a831f38d322323bc8aeef9790da4111   \n",
       "27  5a831f38d322323bc8aeef9790da4111   \n",
       "28  5a831f38d322323bc8aeef9790da4111   \n",
       "29  5a831f38d322323bc8aeef9790da4111   \n",
       "30  6b4b915850836047cbb546c20c7442d3   \n",
       "31  6b4b915850836047cbb546c20c7442d3   \n",
       "32  920d7f742dc7fc3aa6ca183ca630c4d8   \n",
       "\n",
       "                                           table_path table_cluster col_id  \n",
       "23  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      3  \n",
       "24  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      3  \n",
       "25  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      4  \n",
       "26  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      5  \n",
       "27  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      7  \n",
       "28  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      8  \n",
       "29  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      9  \n",
       "30  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      1  \n",
       "31  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      2  \n",
       "32  /home/fatemeh/ED-Scale/Old_Files/Benchmarks/ka...             1      1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/mediate_files/col_grouping_res/col_df_res/col_df_labels_cluster_1.pickle', 'rb') as f:\n",
    "    col_df_labels = pickle.load(f)\n",
    "df_col = pd.DataFrame.from_dict(col_df_labels, orient='index').T\n",
    "df_col[\"table_path\"].unique()\n",
    "df_col[df_col['column_cluster_label'] == 15]\n",
    "# df_col[df_col['column_cluster_label'] == 0]['col_value'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 6)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_col_clusters: 13\n",
      "***************************************************************\n",
      "0\n",
      "[nan, nan, nan, nan, nan]\n",
      "***************************************************************\n",
      "1\n",
      "['QHU36843', 'QHU36825', 'QHU36855', 'QHO60594', 'QHU79212']\n",
      "[96, 121, 13467, 419, 121]\n",
      "***************************************************************\n",
      "2\n",
      "['orf1a polyprotein [Severe acute respiratory syndrome coronavirus 2]', 'nucleocapsid phosphoprotein [Severe acute respiratory syndrome coronavirus 2]', 'orf1ab polyprotein [Severe acute respiratory syndrome coronavirus 2]', 'envelope protein [Severe acute respiratory syndrome coronavirus 2]', 'orf8 protein [Severe acute respiratory syndrome coronavirus 2]']\n",
      "['Severe acute respiratory syndrome-related coronavirus', 'Severe acute respiratory syndrome-related coronavirus', 'Severe acute respiratory syndrome-related coronavirus', 'Severe acute respiratory syndrome-related coronavirus', 'Severe acute respiratory syndrome-related coronavirus']\n",
      "***************************************************************\n",
      "3\n",
      "['Betacoronavirus', 'Betacoronavirus', 'Betacoronavirus', 'Betacoronavirus', 'Betacoronavirus']\n",
      "***************************************************************\n",
      "4\n",
      "['Coronaviridae', 'Coronaviridae', 'Coronaviridae', 'Coronaviridae', 'Coronaviridae']\n",
      "***************************************************************\n",
      "5\n",
      "[nan, nan, nan, nan, nan]\n",
      "***************************************************************\n",
      "6\n",
      "[nan, nan, nan, nan, nan]\n",
      "***************************************************************\n",
      "7\n",
      "[nan, nan, nan, nan, nan]\n",
      "***************************************************************\n",
      "8\n",
      "['Japan', 'USA', 'Japan', 'South Korea', 'Japan']\n",
      "***************************************************************\n",
      "9\n",
      "['ORF3a protein', 'envelope protein', 'nonstructural protein NS8', 'orf8 protein', 'surface glycoprotein']\n",
      "['Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens', 'Homo sapiens']\n",
      "***************************************************************\n",
      "10\n",
      "['oronasopharynx', nan, nan, nan, 'oronasopharynx']\n",
      "***************************************************************\n",
      "11\n",
      "['2020-02-05T00:00:00Z', '2020-02-12T00:00:00Z', '2020-02-06T00:00:00Z', '2020-01-29T00:00:00Z', '2020-01-29T00:00:00Z']\n",
      "['2020-01-31', '2020-01-27', '2019-12-30', '2020-01', '2020-01-28']\n",
      "***************************************************************\n",
      "12\n",
      "[nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n_col_clusters = df_col['column_cluster_label'].max() + 1\n",
    "print(\"n_col_clusters:\", n_col_clusters)\n",
    "\n",
    "for i in range(n_col_clusters):\n",
    "    print(\"***************************************************************\")\n",
    "    print(i)\n",
    "    d = df_col[df_col['column_cluster_label'] == i]\n",
    "    for i, r in d.iterrows():\n",
    "        print(random.sample(r['col_value'], 5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18 + 24 + 7 + 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results/tables_dict.pickle', 'rb') as f:\n",
    "    table_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raha Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_budget: 1, dataset: best_sellers, execution_number: 1\n",
      "label_budget: 1, dataset: disney, execution_number: 1\n",
      "label_budget: 1, dataset: marvels, execution_number: 1\n",
      "label_budget: 1, dataset: 1, execution_number: 1\n",
      "label_budget: 1, dataset: cou_1, execution_number: 1\n",
      "label_budget: 1, dataset: 2, execution_number: 1\n",
      "label_budget: 1, dataset: imdb, execution_number: 1\n",
      "label_budget: 1, dataset: cou_2, execution_number: 1\n",
      "label_budget: 1, dataset: best_sellers, execution_number: 2\n",
      "label_budget: 1, dataset: disney, execution_number: 2\n",
      "label_budget: 1, dataset: marvels, execution_number: 2\n",
      "label_budget: 1, dataset: 1, execution_number: 2\n",
      "label_budget: 1, dataset: cou_1, execution_number: 2\n",
      "label_budget: 1, dataset: 2, execution_number: 2\n",
      "label_budget: 1, dataset: imdb, execution_number: 2\n",
      "label_budget: 1, dataset: cou_2, execution_number: 2\n",
      "label_budget: 1, dataset: best_sellers, execution_number: 3\n",
      "label_budget: 1, dataset: disney, execution_number: 3\n",
      "label_budget: 1, dataset: marvels, execution_number: 3\n",
      "label_budget: 1, dataset: 1, execution_number: 3\n",
      "label_budget: 1, dataset: cou_1, execution_number: 3\n",
      "label_budget: 1, dataset: 2, execution_number: 3\n",
      "label_budget: 1, dataset: imdb, execution_number: 3\n",
      "label_budget: 1, dataset: cou_2, execution_number: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "repition = range(1, 4)\n",
    "labeling_budgets = range(1, 2)\n",
    "sandbox_path = \"/home/fatemeh/ED-Scale/Old_Files/Benchmarks/kaggle_sample_dataset/separated_kaggle_lake/kaggle_sample_sandbox\"\n",
    "results_path = \"/home/fatemeh/ED-Scale/Old_Files/Benchmarks/kaggle_sample_dataset/results\"\n",
    "dir_levels = 1 # That means we have files in each subdirectory of sandbox dir\n",
    "# datasets = [\"best_sellers\", \"1\", \"2\", \"cou_1\", \"cou_2\", \"disney\", \"imdb\", \"marvels\"]\n",
    "datasets = []\n",
    "algorithm = 'raha'\n",
    "\n",
    "\n",
    "if dir_levels == 1:\n",
    "    for dir in os.listdir(sandbox_path):\n",
    "        datasets.append(dir)\n",
    "\n",
    "# \"actuall_errors_json\":[]\n",
    "\n",
    "results_dict = {\"algorithm\":[], \"dataset\":[], \"execution_number\":[], \n",
    "              \"precision\": [], \"recall\": [], \"f_score\": [],\n",
    "                \"tp\": [], \"ed_tpfp\": [], \"ed_tpfn\": [], \"execution_time\": [],\n",
    "                 \"number_of_labeled_tuples\": [], \"number_of_labeled_cells\": [], \"detected_errors_keys\":[]}\n",
    "count = 0 \n",
    "d = []\n",
    "no_errors_files = []\n",
    "raha_erros_file = []\n",
    "for i in repition:\n",
    "    for dataset in datasets:\n",
    "        if dataset not in no_errors_files and dataset not in raha_erros_file:\n",
    "            for label_budget in labeling_budgets:\n",
    "                print(\"label_budget: {}, dataset: {}, execution_number: {}\".format(label_budget, dataset, i))\n",
    "                # \"/{}_labels_{}_execution\".format(label_budget, i) +\n",
    "                file_path = results_path + '/{}_{}_number#{}_${}$labels.json'\\\n",
    "                            .format(algorithm, dataset, str(i), str(label_budget))\n",
    "                # print(file_path)\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path) as file:\n",
    "                        json_content = json.load(file)\n",
    "                        results_dict['algorithm'].append(algorithm)\n",
    "                        results_dict['dataset'].append(dataset)\n",
    "                        # results_dict['dataset_shape'].append(json_content['dataset_shape'])\n",
    "                        results_dict['execution_number'].append(i)\n",
    "                        results_dict['precision'].append(json_content['precision'])\n",
    "                        results_dict['recall'].append(json_content['recall'])\n",
    "                        results_dict['f_score'].append(json_content['f_score'])\n",
    "                        results_dict['tp'].append(json_content['tp'])\n",
    "                        results_dict['ed_tpfp'].append(json_content['ed_tpfp'])\n",
    "                        results_dict['ed_tpfn'].append(json_content['ed_tpfn'])\n",
    "                        results_dict['execution_time'].append(json_content['execution-time'])\n",
    "                        results_dict['number_of_labeled_tuples'].append(json_content['number_of_labeled_tuples'])\n",
    "                        results_dict['number_of_labeled_cells'].append(json_content['number_of_labeled_cells'])\n",
    "                        # results_dict['actuall_errors_json'].append(json_content['actuall_errors_json'])\n",
    "                        results_dict['detected_errors_keys'].append(json_content['detected_errors_keys'])\n",
    "                else:\n",
    "                    print(\"The file does not exist: {}\".format(file_path))\n",
    "                    print()\n",
    "        \n",
    "result_df = pd.DataFrame.from_dict(results_dict)\n",
    "# result_df.to_csv(\"/Users/fatemehahmadi/Documents/Github-Private/ED-Scale/marshmallow_pipeline/kaggle_raha/raha-dtype-orig/results_all_{}.csv\".format(algorithm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>dataset</th>\n",
       "      <th>execution_number</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "      <th>tp</th>\n",
       "      <th>ed_tpfp</th>\n",
       "      <th>ed_tpfn</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>number_of_labeled_tuples</th>\n",
       "      <th>number_of_labeled_cells</th>\n",
       "      <th>detected_errors_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raha</td>\n",
       "      <td>best_sellers</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178</td>\n",
       "      <td>0.187407</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raha</td>\n",
       "      <td>disney</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.164836</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raha</td>\n",
       "      <td>marvels</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10070</td>\n",
       "      <td>655.769868</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raha</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.140976</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raha</td>\n",
       "      <td>cou_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.172973</td>\n",
       "      <td>32.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.174839</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[[0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>raha</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.376129</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>raha</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247</td>\n",
       "      <td>1.004929</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>raha</td>\n",
       "      <td>cou_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.269205</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm       dataset  execution_number  precision  recall   f_score  \\\n",
       "0      raha  best_sellers                 1   0.000000    0.00  0.000000   \n",
       "1      raha        disney                 1   0.000000    0.00  0.000000   \n",
       "2      raha       marvels                 1   0.000000    0.00  0.000000   \n",
       "3      raha             1                 1   0.000000    0.00  0.000000   \n",
       "4      raha         cou_1                 1   0.132231    0.25  0.172973   \n",
       "5      raha             2                 1   0.000000    0.00  0.000000   \n",
       "6      raha          imdb                 1   0.000000    0.00  0.000000   \n",
       "7      raha         cou_2                 1   0.000000    0.00  0.000000   \n",
       "\n",
       "     tp  ed_tpfp  ed_tpfn  execution_time  number_of_labeled_tuples  \\\n",
       "0   0.0      0.0      178        0.187407                         1   \n",
       "1   0.0      0.0      122        0.164836                         1   \n",
       "2   0.0      0.0    10070      655.769868                         1   \n",
       "3   0.0      0.0       90        0.140976                         1   \n",
       "4  32.0    242.0      128        0.174839                         1   \n",
       "5   0.0      0.0      115        0.376129                         1   \n",
       "6   0.0      0.0      247        1.004929                         1   \n",
       "7   0.0      0.0       74        0.269205                         1   \n",
       "\n",
       "   number_of_labeled_cells                               detected_errors_keys  \n",
       "0                        7                                                 []  \n",
       "1                        6                                                 []  \n",
       "2                       12                                                 []  \n",
       "3                        8                                                 []  \n",
       "4                       13  [[0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2...  \n",
       "5                       17                                                 []  \n",
       "6                       14                                                 []  \n",
       "7                       21                                                 []  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df[\"execution_number\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1322314049586777 0.002902757619738752 0.005680809515355939\n",
      "98\n",
      "0.12833333333333333 0.006984760522496371 0.01324845147969718\n",
      "98\n",
      "0.098969129923245 0.32048258345428154 0.1512349642566671\n",
      "98\n",
      "0.11984462273841867 0.11012336719883888 0.05672140841724008\n"
     ]
    }
   ],
   "source": [
    "pp, rr, ff = 0, 0, 0\n",
    "for i in range(1, 4):\n",
    "    df = result_df[result_df['execution_number'] == i]\n",
    "    p = sum(df['tp'])/(sum(df['ed_tpfp']))\n",
    "    r = sum(df['tp'])/(sum(df['ed_tpfn']))\n",
    "    f_score = 2*p*r/(p+r)\n",
    "    print(p, r, f_score)\n",
    "    print(df[\"number_of_labeled_cells\"].sum())\n",
    "    pp += p\n",
    "    rr += r\n",
    "    ff += f_score\n",
    "print(pp/3, rr/3, ff/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results/results_df.pickle', 'rb') as f:\n",
    "    results_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_shape</th>\n",
       "      <th>col_id</th>\n",
       "      <th>col_name</th>\n",
       "      <th>cell_idx</th>\n",
       "      <th>cell_value</th>\n",
       "      <th>predicted</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [table_id, table_name, table_shape, col_id, col_name, cell_idx, cell_value, predicted, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results\"\n",
    "all_col_clusters_scores = []\n",
    "for f in os.listdir(results_path):\n",
    "    if f.startswith('scores_col_cluster_'):\n",
    "        scores = pickle.load(open(os.path.join(results_path, f), 'rb'))\n",
    "        all_col_clusters_scores.append(scores)\n",
    "all_col_clusters_scores_df = pd.DataFrame.from_dict(all_col_clusters_scores)\n",
    "all_col_clusters_scores_df.to_csv(os.path.join(results_path, 'all_col_clusters_scores.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960021831082003"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3926120194185592\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(all_col_clusters_scores)\n",
    "print(df['tp'].sum()/(df['tp'].sum() + df['fp'].sum()))\n",
    "ae = (\"Actual Errors:\", df['tp'].sum() + df['fn'].sum())\n",
    "tt = (\"All values:\", df['tp'].sum() + df['fn'].sum() + df['fp'].sum() + df['tn'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/fatemeh/ED-Scale/marshmallow_pipeline/output/results/results_per_table.pickle', 'rb') as f:\n",
    "    results_per_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_per_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Error-Detection-at-Scale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
